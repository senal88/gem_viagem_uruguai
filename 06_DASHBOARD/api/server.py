#!/usr/bin/env python3
"""
Servidor Flask para Dashboard GEM Expert
API para chat e dados da viagem
"""

import os
import json
import sys
from datetime import datetime
from flask import Flask, render_template, request, jsonify
from flask_cors import CORS
from dotenv import load_dotenv

# Adicionar diretÃ³rio de integraÃ§Ãµes ao path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '../../07_INTEGRACOES/03_ALUGUEL_CARROS'))

# Carregar variÃ¡veis de ambiente
load_dotenv()

app = Flask(__name__,
            template_folder='../templates',
            static_folder='../static',
            static_url_path='/gem/static')
CORS(app)

# Registrar blueprints de integraÃ§Ãµes
try:
    from api_endpoints import bp as car_rental_bp
    app.register_blueprint(car_rental_bp)
except ImportError:
    print("âš ï¸  MÃ³dulo de aluguel de carros nÃ£o disponÃ­vel")

# Registrar integraÃ§Ãµes
try:
    from integrations.weather import bp as weather_bp
    app.register_blueprint(weather_bp)
except ImportError:
    print("âš ï¸  MÃ³dulo de clima nÃ£o disponÃ­vel")

try:
    from integrations.exchange import bp as exchange_bp
    app.register_blueprint(exchange_bp)
except ImportError:
    print("âš ï¸  MÃ³dulo de cÃ¢mbio nÃ£o disponÃ­vel")

try:
    from integrations.maps import bp as maps_bp
    app.register_blueprint(maps_bp)
except ImportError:
    print("âš ï¸  MÃ³dulo de mapas nÃ£o disponÃ­vel")

# Configurar path base para funcionar com Nginx em /gem
APPLICATION_ROOT = '/gem'

# ConfiguraÃ§Ãµes
app.config['SECRET_KEY'] = os.getenv('SECRET_KEY', 'dev-secret-key-change-in-production')

# Dados da viagem (carregar do arquivo JSON quando disponÃ­vel)
TRIP_DATA = {
    'reservations': [
        {
            'date': '2025-11-19',
            'time': '09:30',
            'name': 'Pizzorno Tour',
            'location': 'MontevidÃ©u',
            'type': 'tour'
        },
        {
            'date': '2025-11-20',
            'time': '18:30',
            'name': 'PrÃ©-Wedding L\'Incanto',
            'location': 'Punta del Este',
            'type': 'event'
        },
        {
            'date': '2025-11-22',
            'time': '16:30',
            'name': 'Casamento Fasano',
            'location': 'Punta del Este',
            'type': 'event'
        },
        {
            'date': '2025-11-23',
            'time': '20:30',
            'name': 'Primuseum',
            'location': 'MontevidÃ©u',
            'type': 'event'
        },
        {
            'date': '2025-11-24',
            'time': '10:30',
            'name': 'Bouza Tour',
            'location': 'MontevidÃ©u',
            'type': 'tour'
        }
    ]
}

# System prompt para o GEM Expert
SYSTEM_PROMPT = """VocÃª Ã© o concierge de viagem pessoal e de elite para Aline Torres e Luiz Fernando Sena durante sua viagem especÃ­fica ao Uruguai, de 18 a 25 de novembro de 2025.

Sua missÃ£o nÃ£o Ã© criar um roteiro (ele jÃ¡ estÃ¡ definido), mas sim executÃ¡-lo com perfeiÃ§Ã£o, fornecendo suporte dinÃ¢mico, proativo e em tempo real.

INFORMAÃ‡Ã•ES DA VIAGEM:
- Viajantes: Aline Torres + Luiz Fernando Sena (Casal)
- PerÃ­odo: 18 a 25 de novembro de 2025 (8 dias)
- Destinos: MontevidÃ©u (MVD) â†’ Punta del Este (PDE) â†’ MontevidÃ©u (MVD)
- Hotel PDE: Barradas Parque Hotel & Spa (Reserva #6417055860)

RESERVAS CONFIRMADAS:
- 19/11 09:30: Pizzorno Tour (MontevidÃ©u)
- 20/11 18:30: PrÃ©-Wedding L'Incanto (PDE)
- 22/11 16:30: Casamento Fasano Las Piedras (PDE)
- 23/11 20:30: Primuseum (MontevidÃ©u)
- 24/11 10:30: Bouza Tour (MontevidÃ©u)

REGRAS CRÃTICAS DE CONDUÃ‡ÃƒO:
1. âš ï¸ FarÃ³is obrigatÃ³rios ligados 24/7
2. âš ï¸ TolerÃ¢ncia ZERO para Ã¡lcool
3. âš ï¸ PedÃ¡gios via tag Telepeaje

Responda em portuguÃªs, com tom sofisticado e prestativo (concierge de elite)."""

@app.route('/')
@app.route('/gem')
@app.route('/gem/')
def index():
    """PÃ¡gina principal do dashboard"""
    return render_template('index.html')

@app.route('/gem/analise-carros')
@app.route('/gem/analise-carros/')
def analise_carros():
    """PÃ¡gina de anÃ¡lise comparativa de carros"""
    return render_template('analise_carros.html')

@app.route('/api/chat', methods=['POST'])
@app.route('/gem/api/chat', methods=['POST'])
def chat():
    """Endpoint para chat com GEM Expert"""
    try:
        data = request.json
        message = data.get('message', '')
        provider = data.get('provider', 'openai')
        history = data.get('history', [])

        if not message:
            return jsonify({'error': 'Mensagem vazia'}), 400

        # Processar mensagem com o provider selecionado
        response = process_chat(message, provider, history)

        return jsonify({
            'response': response,
            'provider': provider,
            'timestamp': datetime.now().isoformat()
        })

    except Exception as e:
        print(f"Erro no chat: {str(e)}")
        return jsonify({'error': str(e)}), 500

def process_chat(message, provider, history):
    """Processar mensagem com o provider selecionado"""

    if provider == 'openai':
        return chat_openai(message, history)
    elif provider == 'anthropic':
        return chat_anthropic(message, history)
    elif provider == 'gemini':
        return chat_gemini(message, history)
    else:
        return "Provider nÃ£o suportado"

def chat_openai(message, history):
    """Chat com OpenAI"""
    try:
        from openai import OpenAI

        api_key = os.getenv('OPENAI_API_KEY')

        # Verificar se API key estÃ¡ configurada
        if not api_key or api_key.strip() == '':
            return "âš ï¸ OpenAI API Key nÃ£o configurada. Configure OPENAI_API_KEY no arquivo .env para usar o chat com GPT-4."

        client = OpenAI(api_key=api_key)

        messages = [{"role": "system", "content": SYSTEM_PROMPT}]

        # Adicionar histÃ³rico
        for h in history:
            messages.append({"role": h['role'], "content": h['content']})

        # Adicionar mensagem atual
        messages.append({"role": "user", "content": message})

        response = client.chat.completions.create(
            model=os.getenv('OPENAI_MODEL', 'gpt-4-turbo-preview'),
            messages=messages,
            max_tokens=2000,
            temperature=0.7
        )

        return response.choices[0].message.content

    except ImportError:
        return "OpenAI SDK nÃ£o instalado. Execute: pip install openai"
    except Exception as e:
        error_msg = str(e)
        if "401" in error_msg or "API key" in error_msg:
            return "âš ï¸ OpenAI API Key nÃ£o configurada ou invÃ¡lida. Configure OPENAI_API_KEY no arquivo .env. Veja o guia: 07_INTEGRACOES/GUIA_COMPLETO_API_KEYS.md"
        return f"Erro ao processar com OpenAI: {error_msg}"

def chat_anthropic(message, history):
    """Chat com Anthropic"""
    try:
        import anthropic

        api_key = os.getenv('ANTHROPIC_API_KEY')

        # Verificar se API key estÃ¡ configurada
        if not api_key or api_key.strip() == '':
            return "âš ï¸ Anthropic API Key nÃ£o configurada. Configure ANTHROPIC_API_KEY no arquivo .env para usar o chat com Claude."

        client = anthropic.Anthropic(api_key=api_key)

        # Construir mensagens
        messages = []
        for h in history:
            if h['role'] != 'system':
                messages.append({"role": h['role'], "content": h['content']})

        messages.append({"role": "user", "content": message})

        response = client.messages.create(
            model=os.getenv('ANTHROPIC_MODEL', 'claude-3-5-sonnet-20241022'),
            max_tokens=2000,
            system=SYSTEM_PROMPT,
            messages=messages
        )

        return response.content[0].text

    except ImportError:
        return "Anthropic SDK nÃ£o instalado. Execute: pip install anthropic"
    except Exception as e:
        error_msg = str(e)
        if "401" in error_msg or "API key" in error_msg or "credit balance" in error_msg:
            return "âš ï¸ Anthropic API Key nÃ£o configurada ou sem crÃ©ditos. Configure ANTHROPIC_API_KEY no arquivo .env e adicione crÃ©ditos. Veja o guia: 07_INTEGRACOES/GUIA_COMPLETO_API_KEYS.md"
        return f"Erro ao processar com Anthropic: {error_msg}"

def chat_gemini(message, history):
    """Chat com Gemini"""
    try:
        import google.generativeai as genai

        api_key = os.getenv('GOOGLE_API_KEY')

        # Verificar se API key estÃ¡ configurada
        if not api_key or api_key.strip() == '':
            return "âš ï¸ Google API Key nÃ£o configurada. Configure GOOGLE_API_KEY no arquivo .env para usar o chat com Gemini."

        genai.configure(api_key=api_key)

        model = genai.GenerativeModel(
            model_name=os.getenv('GOOGLE_MODEL', 'gemini-2.5-pro'),
            system_instruction=SYSTEM_PROMPT
        )

        # Construir contexto do histÃ³rico
        context = "\n".join([
            f"{'UsuÃ¡rio' if h['role'] == 'user' else 'Assistente'}: {h['content']}"
            for h in history[-5:]  # Ãšltimas 5 mensagens
        ])

        full_message = f"{context}\n\nUsuÃ¡rio: {message}" if context else message

        response = model.generate_content(full_message)

        return response.text

    except ImportError:
        return "Google Generative AI SDK nÃ£o instalado. Execute: pip install google-generativeai"
    except Exception as e:
        return f"Erro ao processar com Gemini: {str(e)}"

@app.route('/api/weather', methods=['GET'])
@app.route('/gem/api/weather', methods=['GET'])
def weather_legacy():
    """Endpoint legado para dados do clima (redireciona para novo)"""
    # Redirecionar para novo endpoint
    from integrations.weather import get_current_weather
    weather = get_current_weather()
    if weather:
        return jsonify(weather)
    return jsonify({
        'temp': 22,
        'description': 'Parcialmente nublado',
        'wind': 15,
        'humidity': 65,
        'note': 'Dados simulados'
    })

@app.route('/api/exchange', methods=['GET'])
@app.route('/gem/api/exchange', methods=['GET'])
def exchange_legacy():
    """Endpoint legado para cÃ¢mbio (redireciona para novo)"""
    # Redirecionar para novo endpoint
    from integrations.exchange import get_exchange_rate
    rate = get_exchange_rate()
    if rate:
        return jsonify(rate)
    return jsonify({
        'rate': 7.45,
        'currency': 'UYU',
        'base': 'BRL',
        'note': 'Dados simulados'
    })

@app.route('/api/reservations', methods=['GET'])
def reservations():
    """Endpoint para reservas"""
    return jsonify(TRIP_DATA['reservations'])

@app.route('/api/next-event', methods=['GET'])
def next_event():
    """Endpoint para prÃ³ximo evento"""
    today = datetime.now().date().isoformat()

    upcoming = [
        r for r in TRIP_DATA['reservations']
        if r['date'] >= today
    ]

    if upcoming:
        upcoming.sort(key=lambda x: (x['date'], x['time']))
        return jsonify(upcoming[0])

    return jsonify({'message': 'Nenhum evento prÃ³ximo'})

if __name__ == '__main__':
    port = int(os.getenv('PORT', 5000))
    debug = os.getenv('FLASK_DEBUG', 'False').lower() == 'true'
    env = os.getenv('FLASK_ENV', 'development')

    if env == 'production':
        # ProduÃ§Ã£o: apenas escutar localhost (nginx faz proxy)
        host = '127.0.0.1'
        print(f"ðŸš€ Servidor iniciando em modo PRODUÃ‡ÃƒO")
        print(f"ðŸ“± Acesse via: http://senamfo.com.br/gem")
    else:
        # Desenvolvimento: escutar todas as interfaces
        host = '0.0.0.0'
        print(f"ðŸš€ Servidor iniciando na porta {port}")
        print(f"ðŸ“± Acesse no iPhone: http://[SEU_IP_LOCAL]:{port}")

    app.run(host=host, port=port, debug=debug)

